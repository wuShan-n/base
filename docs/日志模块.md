# 日志模块开发规划

## 1. 目标与范围
- 统一标准化应用日志，覆盖 `info`、`warn`、`error` 级别以及关键业务审计事件。
- 支持跨服务链路追踪，结合 Micrometer Tracing 与 OpenTelemetry。
- 实现日志的结构化输出、集中收集、存储查询与告警联动。
- 首期聚焦 API 层、服务层（`src/main/java/com/example/base/*`），后续扩展到批处理与任务模块。

## 2. 技术选型
- **日志打印**：Spring Boot 3 默认 Logback，配合 `net.logstash.logback:logstash-logback-encoder` 输出 JSON。
- **链路追踪**：Micrometer Tracing + OpenTelemetry（OTLP 协议 → Collector）。
- **采集层**：Kubernetes 使用 Fluent Bit 或 Grafana Agent DaemonSet/Sidecar 采集 stdout。
- **存储与查询**：Grafana Loki（日志）、Prometheus（指标）、Tempo（可选追踪）。
- **告警**：Grafana Alerting / Alertmanager，对接企业通知渠道。

## 3. 系统设计与目录规划
- `src/main/resources/logback-spring.xml`：定义 appender、encoder、日志级别。
- `src/main/java/com/example/base/common/logging`：新增公共配置（结构化 MDC、审计埋点工具类）。
- `application.yml`：增加日志级别、OTLP 导出端点、抽取租户隔离配置。
- `docs/openapi`：必要时补充关键接口的日志字段说明。

## 4. 开发步骤
1. 基线梳理：审查现有日志输出，列出需要保留与清理的日志点。
2. 引入依赖与配置：添加 logstash encoder、Micrometer Tracing 依赖，编写 `logback-spring.xml`。
3. 结构化扩展：统一 MDC 字段（`requestId`、`tenantId`、`userId`、`spanId`），包装业务日志工具。
4. 链路追踪：配置 OTLP 导出，验证与 Tempo/Grafana Trace 的连通。
5. 集中采集：在部署脚本中配置 Fluent Bit / Grafana Agent，校验向 Loki 写入。
6. 验证与调优：回放关键场景，检查日志字段完整性、采集延迟与告警阈值。

## 5. 验收标准
- `mvn clean verify` 通过，新增/调整的测试覆盖审计点与日志工具。
- 在测试环境中可通过 Grafana/Loki 查询到结构化日志，字段包含 `tenantId`、`traceId`。
- 链路追踪跨服务展示完整调用链，错误日志触发告警规则。
- 文档更新：本文件、`README` 或 `AGENTS.md` 指向日志模块配置步骤。

## 6. 风险与应对
- **高吞吐带来写入压力**：设置异步 appender 并监控队列长度。
- **敏感信息泄露**：规范日志内容，过滤 PII，提供拦截器进行字段脱敏。
- **多租户隔离**：TenantFilter 强制写入 `tenantId`，在 Loki 中以 label 隔离查询。
- **采集链路异常**：配置本地回退文件或 stdout 保底，结合告警快速发现 Collector 故障。
